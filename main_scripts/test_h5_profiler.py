#!/usr/bin/env python3
"""
Test script for HDF5 profiler data import and display.

This script tests the import and display of HDF5 profiling data generated by the NaviFlow profiler.
"""

import os
import sys
import h5py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import json

# Custom JSON encoder to handle NumPy types
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        return super(NumpyEncoder, self).default(obj)

def display_h5_metadata(file_path):
    """Display HDF5 metadata in a nice format"""
    print(f"Loading HDF5 file: {file_path}")
    
    with h5py.File(file_path, 'r') as f:
        # Function to recursively extract group attributes
        def extract_attrs(group):
            result = {}
            # Get attributes
            for key, value in group.attrs.items():
                result[key] = value
            
            # Process subgroups
            for key in group.keys():
                if isinstance(group[key], h5py.Group):
                    result[key] = extract_attrs(group[key])
            
            return result
        
        # Extract all metadata
        metadata = {}
        for key in f.keys():
            if key != 'residual_history':  # Skip the residual history
                metadata[key] = extract_attrs(f[key])
        
        # Display as formatted JSON using the custom encoder
        print(f"\nMetadata:\n{json.dumps(metadata, indent=2, cls=NumpyEncoder)}")
        
        # Return the metadata as a dictionary
        return metadata

def load_residual_history(file_path):
    """Load residual history from HDF5 file as a pandas DataFrame"""
    with h5py.File(file_path, 'r') as f:
        if 'residual_history' in f:
            # Extract all datasets in the residual_history group
            data = {}
            for key in f['residual_history'].keys():
                data[key] = f['residual_history'][key][:]
            
            # Create DataFrame
            return pd.DataFrame(data)
        else:
            return pd.DataFrame()

def plot_convergence_history(residuals):
    """Plot convergence history from residual data"""
    if residuals.empty:
        print("No residual data to plot")
        return
    
    plt.figure(figsize=(10, 6))
    plt.semilogy(residuals['iteration'], residuals['total_residual'], label='Total')
    plt.semilogy(residuals['iteration'], residuals['momentum_residual'], label='Momentum')
    plt.semilogy(residuals['iteration'], residuals['pressure_residual'], label='Pressure')
    plt.xlabel('Iteration')
    plt.ylabel('Residual')
    plt.title('Convergence History')
    plt.legend()
    plt.grid(True)
    
    # Save the plot
    plt.savefig('convergence_history.png')
    print("Convergence history plot saved to 'convergence_history.png'")
    
    # Show the plot if running in interactive mode
    if plt.isinteractive():
        plt.show()

def main():
    """Main function to test HDF5 profiler data import and display"""
    # Find the most recent HDF5 profile file in the geo_multigrid/results directory
    profile_dir = os.path.join(os.path.dirname(__file__), 'geo_multigrid', 'results')
    
    if not os.path.exists(profile_dir):
        print(f"Profile directory not found: {profile_dir}")
        return
    
    h5_files = [f for f in os.listdir(profile_dir) if f.endswith('.h5')]
    
    if not h5_files:
        print(f"No HDF5 files found in {profile_dir}")
        return
    
    # Sort by modification time (newest first)
    h5_files.sort(key=lambda f: os.path.getmtime(os.path.join(profile_dir, f)), reverse=True)
    
    # Get the most recent file
    latest_file = os.path.join(profile_dir, h5_files[0])
    print(f"Found latest HDF5 file: {latest_file}")
    
    # Display metadata
    metadata = display_h5_metadata(latest_file)
    
    # Load and display residual history
    residuals = load_residual_history(latest_file)
    print("\nResidual History (first 5 rows):")
    print(residuals.head())
    
    # Plot convergence history
    plot_convergence_history(residuals)
    
    # Test if all expected data is present
    test_metadata(metadata)
    test_residuals(residuals)
    
    print("\nTest completed successfully!")

def test_metadata(metadata):
    """Test if all expected metadata is present"""
    # Check if all main groups are present
    expected_groups = ['simulation', 'performance', 'convergence', 'system', 'algorithm', 'pressure_solver', 'momentum_solver']
    missing_groups = [g for g in expected_groups if g not in metadata]
    
    if missing_groups:
        print(f"WARNING: Missing metadata groups: {missing_groups}")
    else:
        print("All expected metadata groups are present")
    
    # Check if algorithm parameters are present
    if 'algorithm' in metadata:
        if 'alpha_p' not in metadata['algorithm'] or 'alpha_u' not in metadata['algorithm']:
            print("WARNING: Missing algorithm relaxation factors")
    
    # Check if pressure solver parameters are present
    if 'pressure_solver' in metadata:
        if 'type' not in metadata['pressure_solver']:
            print("WARNING: Missing pressure solver type")
        
        # Check for multigrid parameters if it's a multigrid solver
        if metadata['pressure_solver'].get('type') == 'MultiGridSolver':
            if 'multigrid' not in metadata['pressure_solver']:
                print("WARNING: Missing multigrid parameters")
            elif 'cycle_type' not in metadata['pressure_solver']['multigrid']:
                print("WARNING: Missing multigrid cycle type")

def test_residuals(residuals):
    """Test if all expected residual data is present"""
    if residuals.empty:
        print("WARNING: No residual data found")
        return
    
    expected_columns = ['iteration', 'wall_time', 'cpu_time', 'total_residual', 'momentum_residual', 'pressure_residual']
    missing_columns = [c for c in expected_columns if c not in residuals.columns]
    
    if missing_columns:
        print(f"WARNING: Missing residual columns: {missing_columns}")
    else:
        print("All expected residual columns are present")
    
    # Check if the number of iterations matches the metadata
    # (We can't do this here since we don't have access to metadata['performance']['iterations'])
    
    # Check if residuals are decreasing (convergence)
    if len(residuals) > 1:
        if residuals['total_residual'].iloc[-1] >= residuals['total_residual'].iloc[0]:
            print("WARNING: Residuals are not decreasing")
        else:
            print("Residuals are decreasing (convergence is happening)")

if __name__ == "__main__":
    main() 